{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoostRegressorHyperparamBostonData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIaul3D8X3IcdK4oTy3HYH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlacasa/Regression/blob/main/XGBoostRegressorHyperparamBostonData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDpF-Ivu-Pkq"
      },
      "source": [
        "!pip install lazypredict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFrTznJV-IGY",
        "outputId": "1d03381e-f0bd-456a-a096-e9bd99b19368"
      },
      "source": [
        "from lazypredict.Supervised import LazyRegressor\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "boston = datasets.load_boston() #Carga de datos\n",
        "X, y = shuffle(boston.data, boston.target, random_state=13) # separar variable dependiente y =  precio medio\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12) # Observar cómo cambia R-Squared del 10% al 25% test\n",
        "\n",
        "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
        "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(models)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 14.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
            "Model                                                                         \n",
            "GradientBoostingRegressor                    0.90       0.91  2.71        0.16\n",
            "HistGradientBoostingRegressor                0.90       0.91  2.76        0.32\n",
            "ExtraTreesRegressor                          0.90       0.91  2.80        0.21\n",
            "LGBMRegressor                                0.89       0.90  2.87        0.07\n",
            "XGBRegressor                                 0.88       0.90  2.95        0.08\n",
            "RandomForestRegressor                        0.87       0.88  3.11        0.34\n",
            "BaggingRegressor                             0.86       0.87  3.30        0.05\n",
            "AdaBoostRegressor                            0.84       0.85  3.52        0.13\n",
            "PoissonRegressor                             0.81       0.83  3.78        0.02\n",
            "DecisionTreeRegressor                        0.80       0.82  3.92        0.02\n",
            "KNeighborsRegressor                          0.78       0.80  4.11        0.03\n",
            "ExtraTreeRegressor                           0.75       0.77  4.35        0.02\n",
            "ElasticNetCV                                 0.73       0.76  4.53        0.09\n",
            "BayesianRidge                                0.73       0.75  4.53        0.01\n",
            "LarsCV                                       0.73       0.75  4.54        0.09\n",
            "LassoLarsCV                                  0.73       0.75  4.54        0.04\n",
            "LassoCV                                      0.73       0.75  4.54        0.08\n",
            "SGDRegressor                                 0.72       0.75  4.55        0.02\n",
            "LassoLarsIC                                  0.72       0.75  4.55        0.02\n",
            "Ridge                                        0.72       0.75  4.55        0.01\n",
            "RidgeCV                                      0.72       0.75  4.55        0.01\n",
            "Lars                                         0.72       0.75  4.56        0.04\n",
            "TransformedTargetRegressor                   0.72       0.75  4.56        0.01\n",
            "LinearRegression                             0.72       0.75  4.56        0.01\n",
            "HuberRegressor                               0.72       0.75  4.60        0.03\n",
            "LinearSVR                                    0.71       0.74  4.64        0.01\n",
            "MLPRegressor                                 0.71       0.74  4.67        0.51\n",
            "OrthogonalMatchingPursuitCV                  0.70       0.73  4.73        0.03\n",
            "GammaRegressor                               0.65       0.68  5.14        0.01\n",
            "Lasso                                        0.64       0.67  5.24        0.02\n",
            "ElasticNet                                   0.63       0.67  5.27        0.01\n",
            "SVR                                          0.63       0.67  5.28        0.03\n",
            "GeneralizedLinearRegressor                   0.63       0.67  5.30        0.02\n",
            "TweedieRegressor                             0.63       0.67  5.30        0.01\n",
            "NuSVR                                        0.62       0.66  5.33        0.04\n",
            "OrthogonalMatchingPursuit                    0.50       0.55  6.14        0.02\n",
            "PassiveAggressiveRegressor                   0.47       0.52  6.34        0.02\n",
            "RANSACRegressor                              0.43       0.49  6.54        0.09\n",
            "GaussianProcessRegressor                     0.23       0.31  7.61        0.04\n",
            "DummyRegressor                              -0.12      -0.00  9.17        0.01\n",
            "LassoLars                                   -0.12      -0.00  9.17        0.02\n",
            "KernelRidge                                 -6.03      -5.30 22.98        0.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQBwUa1m-ucY"
      },
      "source": [
        "# import machine learning libraries\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# import packages for hyperparameters tuning\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLMHa4mh_g4J"
      },
      "source": [
        "# HYPEROPT \n",
        "\n",
        "https://github.com/hyperopt/hyperopt/wiki/FMin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM-OZr1QESr1"
      },
      "source": [
        "**The available hyperopt optimization algorithms are -**\n",
        "\n",
        "\n",
        "* **hp.choice**(label, options) — Escoje una opción entre las ofrecidas.\n",
        "\n",
        "* **hp.randint**(label, upper) — Escoje un valor al azar entre el rango.\n",
        "\n",
        "* **hp.uniform**(label, low, high) — Retorna un valor entre el rango.\n",
        "\n",
        "* **hp.quniform**(label, low, high, q) — Retorna un valor (uniform(low, high) / q) * q, i.e donde q es el intervalo.\n",
        "\n",
        "* **hp.normal**(label, mean, std) — Retorna un valor R, distribuido Normal.\n",
        "\n",
        "Mean Square Error\n",
        "\n",
        "$\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFSjT-j2ID1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc25308-2d1e-4b84-9595-e8bd7690a4d9"
      },
      "source": [
        "# Cargamos librerías de hyperopt\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Escogemos los parámetros a evaluar\n",
        "\n",
        "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
        "        'gamma': hp.uniform ('gamma', 1,9),\n",
        "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
        "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
        "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
        "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
        "        #'n_estimators':180,\n",
        "        'subsample': hp.uniform('subsample', 0.5,1),\n",
        "        'n_estimators': hp.uniform('n_estimators', 100, 500),\n",
        "        'eta': hp.uniform('eta', 0.1, 0.5)\n",
        "    }\n",
        "# Definimos la función que retorna el score\n",
        "def hyperparameter_tuning(space):\n",
        "    model=xgb.XGBRegressor(n_estimators =int(space['n_estimators']), \n",
        "                           max_depth = int(space['max_depth']), \n",
        "                           gamma = space['gamma'],\n",
        "                           reg_alpha = int(space['reg_alpha']),\n",
        "                           min_child_weight=space['min_child_weight'],\n",
        "                           colsample_bytree=space['colsample_bytree'],\n",
        "                           eta = space['eta'],\n",
        "                           subsample = space['subsample'])\n",
        "    \n",
        "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
        "    \n",
        "    model.fit(X_train, y_train,\n",
        "            eval_set=evaluation, eval_metric=\"rmse\",\n",
        "            early_stopping_rounds=10,verbose=False)\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "    mse= mean_squared_error(y_test, pred)\n",
        "    #print (\"SCORE:\", mse)\n",
        "    #Cambiar métrica\n",
        "    return {'loss':mse, 'status': STATUS_OK, 'model': model}    # En regressión, mse.\n",
        " # Definimos el optimizador   \n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn=hyperparameter_tuning,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=500, # Valor importante, normalmente más de 500 no mejora\n",
        "            trials=trials)\n",
        "# Mostramos los valores óptimos\n",
        "print (best)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:56<00:00,  8.92it/s, best loss: 8.154696052536751]\n",
            "{'colsample_bytree': 0.5193697799372575, 'eta': 0.1652210548197838, 'gamma': 3.329155030135193, 'max_depth': 7.0, 'min_child_weight': 3.0, 'n_estimators': 381.397688200051, 'reg_alpha': 51.0, 'reg_lambda': 0.3507176342582392, 'subsample': 0.7333228410584999}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5SYtyawNeDA"
      },
      "source": [
        "# Ejecutamos el modelo con los parámetros seleccionados.\n",
        "\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import absolute\n",
        "\n",
        "model = XGBRegressor(colsample_bytree=0.62,\n",
        "                     eta = 0.21,\n",
        "                     gamma = 2.5,\n",
        "                     max_depth=9, \n",
        "                     min_child_weight=3, \n",
        "                     n_estimators = 167,\n",
        "                     reg_alpha = 43.0, \n",
        "                     reg_lambda = 0.14,\n",
        "                     subsample = 0.89)\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1) # Se repite 3 veces, con 5 grupos train.\n",
        "scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1) # n_jobs = -1, utiliza todos los procesadores posibles.\n",
        "# En caso que scores sea negativo.\n",
        "scores = absolute(scores)\n",
        "print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1spyov3EFlB"
      },
      "source": [
        "Calculamos el R2 score mediante la función:\n",
        "\n",
        "$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0egu0E8N3ug"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "model.fit(X_train, y_train, verbose=False)\n",
        "y_train_pred1 = model.predict(X_train)\n",
        "y_pred1 = model.predict(X_test)\n",
        "print('Train r2 score: ', r2_score(y_train_pred1, y_train))\n",
        "print('Test r2 score: ', r2_score(y_test, y_pred1))\n",
        "train_mse1 = mean_squared_error(y_train_pred1, y_train)\n",
        "test_mse1 = mean_squared_error(y_pred1, y_test)\n",
        "train_rmse1 = np.sqrt(train_mse1)\n",
        "test_rmse1 = np.sqrt(test_mse1)\n",
        "print('Train RMSE: %.4f' % train_rmse1)\n",
        "print('Test RMSE: %.4f' % test_rmse1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwYGZgs4RBpW"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.barh( boston.feature_names, model.feature_importances_)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7NBi9tWSYON"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}