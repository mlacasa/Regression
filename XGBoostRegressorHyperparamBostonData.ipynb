{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoostRegressorHyperparamBostonData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUJxK1FpmS9dkPBRE85Kqz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlacasa/Regression/blob/main/XGBoostRegressorHyperparamBostonData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDpF-Ivu-Pkq"
      },
      "source": [
        "!pip install lazypredict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFrTznJV-IGY",
        "outputId": "1d03381e-f0bd-456a-a096-e9bd99b19368"
      },
      "source": [
        "from lazypredict.Supervised import LazyRegressor\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "boston = datasets.load_boston() #Carga de datos\n",
        "X, y = shuffle(boston.data, boston.target, random_state=13) # separar variable dependiente y =  precio medio\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12) # Observar cómo cambia R-Squared del 10% al 25% test\n",
        "\n",
        "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
        "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(models)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 14.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
            "Model                                                                         \n",
            "GradientBoostingRegressor                    0.90       0.91  2.71        0.16\n",
            "HistGradientBoostingRegressor                0.90       0.91  2.76        0.32\n",
            "ExtraTreesRegressor                          0.90       0.91  2.80        0.21\n",
            "LGBMRegressor                                0.89       0.90  2.87        0.07\n",
            "XGBRegressor                                 0.88       0.90  2.95        0.08\n",
            "RandomForestRegressor                        0.87       0.88  3.11        0.34\n",
            "BaggingRegressor                             0.86       0.87  3.30        0.05\n",
            "AdaBoostRegressor                            0.84       0.85  3.52        0.13\n",
            "PoissonRegressor                             0.81       0.83  3.78        0.02\n",
            "DecisionTreeRegressor                        0.80       0.82  3.92        0.02\n",
            "KNeighborsRegressor                          0.78       0.80  4.11        0.03\n",
            "ExtraTreeRegressor                           0.75       0.77  4.35        0.02\n",
            "ElasticNetCV                                 0.73       0.76  4.53        0.09\n",
            "BayesianRidge                                0.73       0.75  4.53        0.01\n",
            "LarsCV                                       0.73       0.75  4.54        0.09\n",
            "LassoLarsCV                                  0.73       0.75  4.54        0.04\n",
            "LassoCV                                      0.73       0.75  4.54        0.08\n",
            "SGDRegressor                                 0.72       0.75  4.55        0.02\n",
            "LassoLarsIC                                  0.72       0.75  4.55        0.02\n",
            "Ridge                                        0.72       0.75  4.55        0.01\n",
            "RidgeCV                                      0.72       0.75  4.55        0.01\n",
            "Lars                                         0.72       0.75  4.56        0.04\n",
            "TransformedTargetRegressor                   0.72       0.75  4.56        0.01\n",
            "LinearRegression                             0.72       0.75  4.56        0.01\n",
            "HuberRegressor                               0.72       0.75  4.60        0.03\n",
            "LinearSVR                                    0.71       0.74  4.64        0.01\n",
            "MLPRegressor                                 0.71       0.74  4.67        0.51\n",
            "OrthogonalMatchingPursuitCV                  0.70       0.73  4.73        0.03\n",
            "GammaRegressor                               0.65       0.68  5.14        0.01\n",
            "Lasso                                        0.64       0.67  5.24        0.02\n",
            "ElasticNet                                   0.63       0.67  5.27        0.01\n",
            "SVR                                          0.63       0.67  5.28        0.03\n",
            "GeneralizedLinearRegressor                   0.63       0.67  5.30        0.02\n",
            "TweedieRegressor                             0.63       0.67  5.30        0.01\n",
            "NuSVR                                        0.62       0.66  5.33        0.04\n",
            "OrthogonalMatchingPursuit                    0.50       0.55  6.14        0.02\n",
            "PassiveAggressiveRegressor                   0.47       0.52  6.34        0.02\n",
            "RANSACRegressor                              0.43       0.49  6.54        0.09\n",
            "GaussianProcessRegressor                     0.23       0.31  7.61        0.04\n",
            "DummyRegressor                              -0.12      -0.00  9.17        0.01\n",
            "LassoLars                                   -0.12      -0.00  9.17        0.02\n",
            "KernelRidge                                 -6.03      -5.30 22.98        0.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQBwUa1m-ucY"
      },
      "source": [
        "# import machine learning libraries\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# import packages for hyperparameters tuning\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLMHa4mh_g4J"
      },
      "source": [
        "# HYPEROPT \n",
        "\n",
        "https://github.com/hyperopt/hyperopt/wiki/FMin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM-OZr1QESr1"
      },
      "source": [
        "**The available hyperopt optimization algorithms are -**\n",
        "\n",
        "\n",
        "* **hp.choice**(label, options) — Escoje una opción entre las ofrecidas.\n",
        "\n",
        "* **hp.randint**(label, upper) — Escoje un valor al azar entre el rango.\n",
        "\n",
        "* **hp.uniform**(label, low, high) — Retorna un valor entre el rango.\n",
        "\n",
        "* **hp.quniform**(label, low, high, q) — Retorna un valor (uniform(low, high) / q) * q, i.e donde q es el intervalo.\n",
        "\n",
        "* **hp.normal**(label, mean, std) — Retorna un valor R, distribuido Normal.\n",
        "\n",
        "Mean Square Error\n",
        "\n",
        "$\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFSjT-j2ID1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc25308-2d1e-4b84-9595-e8bd7690a4d9"
      },
      "source": [
        "# Cargamos librerías de hyperopt\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Escogemos los parámetros a evaluar\n",
        "\n",
        "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
        "        'gamma': hp.uniform ('gamma', 1,9),\n",
        "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
        "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
        "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
        "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
        "        #'n_estimators':180,\n",
        "        'subsample': hp.uniform('subsample', 0.5,1),\n",
        "        'n_estimators': hp.uniform('n_estimators', 100, 500),\n",
        "        'eta': hp.uniform('eta', 0.1, 0.5)\n",
        "    }\n",
        "# Definimos la función que retorna el score\n",
        "def hyperparameter_tuning(space):\n",
        "    model=xgb.XGBRegressor(n_estimators =int(space['n_estimators']), \n",
        "                           max_depth = int(space['max_depth']), \n",
        "                           gamma = space['gamma'],\n",
        "                           reg_alpha = int(space['reg_alpha']),\n",
        "                           min_child_weight=space['min_child_weight'],\n",
        "                           colsample_bytree=space['colsample_bytree'],\n",
        "                           eta = space['eta'],\n",
        "                           subsample = space['subsample'])\n",
        "    \n",
        "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
        "    \n",
        "    model.fit(X_train, y_train,\n",
        "            eval_set=evaluation, eval_metric=\"rmse\",\n",
        "            early_stopping_rounds=10,verbose=False)\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "    mse= mean_squared_error(y_test, pred)\n",
        "    #print (\"SCORE:\", mse)\n",
        "    #Cambiar métrica\n",
        "    return {'loss':mse, 'status': STATUS_OK, 'model': model}    # En regressión, mse.\n",
        " # Definimos el optimizador   \n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn=hyperparameter_tuning,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=500, # Valor importante, normalmente más de 500 no mejora\n",
        "            trials=trials)\n",
        "# Mostramos los valores óptimos\n",
        "print (best)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:56<00:00,  8.92it/s, best loss: 8.154696052536751]\n",
            "{'colsample_bytree': 0.5193697799372575, 'eta': 0.1652210548197838, 'gamma': 3.329155030135193, 'max_depth': 7.0, 'min_child_weight': 3.0, 'n_estimators': 381.397688200051, 'reg_alpha': 51.0, 'reg_lambda': 0.3507176342582392, 'subsample': 0.7333228410584999}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5SYtyawNeDA",
        "outputId": "fa0fbd37-bee5-448c-e57a-cc0220faa513"
      },
      "source": [
        "# Ejecutamos el modelo con los parámetros seleccionados.\n",
        "\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import absolute\n",
        "\n",
        "model = XGBRegressor(colsample_bytree=0.62,\n",
        "                     eta = 0.21,\n",
        "                     gamma = 2.5,\n",
        "                     max_depth=9, \n",
        "                     min_child_weight=3, \n",
        "                     n_estimators = 167,\n",
        "                     reg_alpha = 43.0, \n",
        "                     reg_lambda = 0.14,\n",
        "                     subsample = 0.89)\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1) # Se repite 3 veces, con 5 grupos train.\n",
        "scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1) # n_jobs = -1, utiliza todos los procesadores posibles.\n",
        "# En caso que scores sea negativo.\n",
        "scores = absolute(scores)\n",
        "print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean MAE: 2.656 (0.275)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1spyov3EFlB"
      },
      "source": [
        "Calculamos el R2 score mediante la función:\n",
        "\n",
        "$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0egu0E8N3ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817148a7-bbc5-42d1-e0ba-355f87e5b712"
      },
      "source": [
        "# Del modelo seleccionado, queremos saber el R-2 Square, y si hay overfitting\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "model.fit(X_train, y_train, verbose=False)\n",
        "y_train_pred1 = model.predict(X_train)\n",
        "y_pred1 = model.predict(X_test)\n",
        "print('Train r2 score: ', r2_score(y_train_pred1, y_train)) # Valor R-2 Square train y test\n",
        "print('Test r2 score: ', r2_score(y_test, y_pred1))\n",
        "train_mse1 = mean_squared_error(y_train_pred1, y_train)\n",
        "test_mse1 = mean_squared_error(y_pred1, y_test)\n",
        "train_rmse1 = np.sqrt(train_mse1) # MSE train y test\n",
        "test_rmse1 = np.sqrt(test_mse1)\n",
        "print('Train RMSE: %.4f' % train_rmse1)\n",
        "print('Test RMSE: %.4f' % test_rmse1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train r2 score:  0.9334839925142836\n",
            "Test r2 score:  0.8934600101927715\n",
            "Train RMSE: 2.2127\n",
            "Test RMSE: 2.9885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "HwYGZgs4RBpW",
        "outputId": "56ce144a-a2d0-4134-c8c2-1c2f409f9b13"
      },
      "source": [
        "# Mostrar las variables más influyentes.\n",
        "\n",
        "from matplotlib import pyplot\n",
        "pyplot.barh( boston.feature_names, model.feature_importances_)\n",
        "pyplot.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7NBi9tWSYON"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}